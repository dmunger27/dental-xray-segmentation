{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmunger27/dental-xray-segmentation/blob/main/Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloudpathlib\n",
        "!pip install boto3\n",
        "!pip install tensorflow\n",
        "!pip install pillow\n",
        "!pip install opencv-python\n",
        "!pip install focal_loss\n",
        "!pip install albumentations"
      ],
      "metadata": {
        "id": "bwelTz_0CtDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from cloudpathlib import CloudPath\n",
        "from cloudpathlib import S3Client\n",
        "from cloudpathlib import S3Path\n",
        "import matplotlib.pyplot as plt\n",
        "import boto3\n",
        "import glob\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
        "from focal_loss import BinaryFocalLoss\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n",
        "import random\n",
        "from keras import backend as K\n"
      ],
      "metadata": {
        "id": "DE3TmI6kClTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variables\n",
        "key_data = pd.read_csv('rootkey.csv')\n",
        "#os.environ['AWS_ACCESS_KEY'] = ''\n",
        "#os.environ['AWS_SECRET_KEY'] = ''"
      ],
      "metadata": {
        "id": "Ne1HQcgPCwWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create files in local storage for x-ray data\n",
        "\n",
        "def gatherS3Data(s3_path, folder_name):\n",
        "  s3_client = S3Client(aws_access_key_id=os.getenv('AWS_ACCESS_KEY'), aws_secret_access_key=os.getenv('AWS_SECRET_KEY'))\n",
        "  x_rays_images = s3_client.CloudPath(s3_path)\n",
        "  x_rays_images.download_to(folder_name)\n",
        "\n",
        "gatherS3Data('s3://ads-599-capstone-data/ads-599-team7/cleaned_abnormalities/', 'abnormality_masks')\n",
        "gatherS3Data('s3://ads-599-capstone-data/ads-599-team7/cleaned_original/', 'original_images')\n",
        "gatherS3Data('s3://ads-599-capstone-data/ads-599-team7/cleaned_teeth/', 'teeth_masks')"
      ],
      "metadata": {
        "id": "KV9GqGW2Cy3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare the data\n",
        "img_size = (256, 256)\n",
        "def load_prep(directory, dim, dtype, color_mode):\n",
        "  data = sorted(glob.glob(directory + '/*'))\n",
        "  num_imgs = len(data)\n",
        "  img_size = (256, 256)\n",
        "  model_imgs = np.zeros((num_imgs,) + img_size + (dim,), dtype=dtype)\n",
        "  for i in range(num_imgs):\n",
        "    if color_mode=='grayscale':\n",
        "      img = load_img(data[i], color_mode=color_mode, target_size=img_size)\n",
        "      img = img.crop((30, 50, 230, 220))\n",
        "      img = img.resize((256, 256))\n",
        "      model_imgs[i] = img_to_array(img) > 100\n",
        "      model_imgs[i] = model_imgs[i].astype('uint8')\n",
        "    else:\n",
        "      img = load_img(data[i], color_mode=color_mode, target_size=img_size)\n",
        "      img = img.crop((30, 50, 230, 220))\n",
        "      img = img.resize((256, 256))\n",
        "      model_imgs[i] = img_to_array(img)\n",
        "  return model_imgs\n",
        "\n",
        "original = load_prep('original_images', 3, 'float32', 'rgb')\n",
        "teeth = load_prep('teeth_masks', 1, 'uint8', 'grayscale')\n",
        "abnormality = load_prep('abnormality_masks', 1, 'uint8', 'grayscale')"
      ],
      "metadata": {
        "id": "bw0It3ZCOnxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter abnormalities to include only visible masks\n",
        "def subset_abnormalities(ab_list):\n",
        "  filtered = []\n",
        "  for i in range(len(ab_list)):\n",
        "    if np.sum(ab_list[i]) > 0:\n",
        "      filtered.append(i)\n",
        "  return filtered\n",
        "\n",
        "subset_list = subset_abnormalities(abnormality)\n",
        "ab_subset = [abnormality[i] for i in subset_list]\n",
        "orig_subset = [original[i] for i in subset_list]\n",
        "num_imgs = len(subset_list)\n",
        "img_size = (256, 256)\n",
        "ab_subset_imgs = np.zeros((num_imgs,) + img_size + (1,), dtype='uint8')\n",
        "orig_subset_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype='float32')\n",
        "for i in range(num_imgs):\n",
        "  ab_subset_imgs[i] = ab_subset[i]\n",
        "  orig_subset_imgs[i] = orig_subset[i]"
      ],
      "metadata": {
        "id": "W0at7VgQZG8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new observations using augmentations\n",
        "# Set augmentations\n",
        "distort = A.GridDistortion(p=1)\n",
        "elastic_trans = A.ElasticTransform(p=1)\n",
        "hflip = A.HorizontalFlip(p=1)\n",
        "aflip = A.VerticalFlip(p=1)\n",
        "transpose = A.Transpose(p=1)\n",
        "\n",
        "augmentation_list = [distort, elastic_trans, hflip, aflip, transpose]\n",
        "\n",
        "# Apply transformation and append to original dataset\n",
        "def transform_and_create(originals, abnormalities, augmentation):\n",
        "  img_size = (256,256)\n",
        "  ab_aug = np.zeros((num_imgs,) + img_size + (1,), dtype='uint8')\n",
        "  orig_aug = np.zeros((num_imgs,) + img_size + (3,), dtype='float32')\n",
        "  for i in range(num_imgs):\n",
        "    augmented = augmentation(image=originals[i], mask=abnormalities[i])\n",
        "    image_aug = augmented['image']\n",
        "    mask_aug = augmented['mask']\n",
        "    ab_aug[i] = mask_aug\n",
        "    orig_aug[i] = image_aug \n",
        "\n",
        "  return ab_aug, orig_aug\n",
        "\n",
        "def append_transform(augmentation_list):\n",
        "  original_list = [orig_subset_imgs]\n",
        "  ab_list = [ab_subset_imgs]\n",
        "  for i in augmentation_list:\n",
        "    aug_abnormality, aug_original = transform_and_create(orig_subset_imgs, ab_subset_imgs, i)\n",
        "    original_list.append(aug_original)\n",
        "    ab_list.append(aug_abnormality)\n",
        "  originals = np.concatenate(original_list, axis=0)\n",
        "  abs = np.concatenate(ab_list, axis=0)\n",
        "\n",
        "  return originals, abs\n",
        "\n",
        "\n",
        "orig_subset_imgs, ab_subset_imgs = append_transform(augmentation_list)"
      ],
      "metadata": {
        "id": "vKvgGFIgSAq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og4rpc99CThx"
      },
      "outputs": [],
      "source": [
        "# Train-test-valid split of data\n",
        "def train_valid_test(array_name):\n",
        "  train, test = train_test_split(array_name, test_size=0.1, random_state=27)\n",
        "  # Train test split again to obtain validation set\n",
        "  train, val = train_test_split(train, test_size=0.1, random_state=27)\n",
        "  return train, val, test\n",
        "\n",
        "\n",
        "train_orig, val_orig, test_orig = train_valid_test(original)\n",
        "train_teeth, val_teeth, test_teeth = train_valid_test(teeth)\n",
        "train_ab, val_ab, test_ab = train_valid_test(ab_subset_imgs)\n",
        "\n",
        "# Subset train and valid\n",
        "sub_train_orig, sub_val_orig, sub_test_orig = train_valid_test(orig_subset_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create up block function\n",
        "def up_block(neurons, concat_layer, input):\n",
        "  up = layers.Conv2DTranspose(neurons, (2,2), strides=(2,2), activation='relu', padding='same')(input)\n",
        "  up = layers.concatenate([up, concat_layer])\n",
        "  conv = layers.Conv2D(neurons, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(up)\n",
        "  conv = layers.Conv2D(neurons, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv)\n",
        "  conv = layers.BatchNormalization()(conv)\n",
        "  return conv"
      ],
      "metadata": {
        "id": "N55PHoblUe5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "# Base model\n",
        "inputs = keras.Input(shape=(256,256) + (3,))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "base = keras.applications.ResNet50V2(\n",
        "      include_top=False,\n",
        "      weights=\"imagenet\",\n",
        "      input_shape=(256,256) + (3,),\n",
        "      input_tensor=x\n",
        "  )\n",
        "base.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwgUJRM7KxLP",
        "outputId": "01c17276-44d5-40c8-e80f-b1fae3f4f29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n",
            "94683136/94668760 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Function for U-Net model\n",
        "def unet_model():\n",
        "  # Extract decoder path\n",
        "  down0 = base.get_layer('input_1').output\n",
        "  down1 = base.get_layer('conv1_conv').output\n",
        "  down2 = base.get_layer('conv2_block3_1_relu').output\n",
        "  down3 = base.get_layer('conv3_block4_1_relu').output\n",
        "  x = base.get_layer('conv4_block6_1_relu').output \n",
        "  conv6 = up_block(512, down3, x)\n",
        "  conv7 = up_block(256, down2, conv6)\n",
        "  conv8 = up_block(128, down1, conv7)\n",
        "  conv9 = up_block(64, down0, conv8)\n",
        "  outputs = layers.Conv2D(1, 1, activation='sigmoid', padding='same')(conv9)\n",
        "\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "Tc-HtaJPEXOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model structure and print the summary\n",
        "model = unet_model()\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "yJNKCKvyL4Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the model for tooth detection\n",
        "keras.backend.clear_session()\n",
        "#base.trainable = True\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss=BinaryFocalLoss(gamma=2, pos_weight=30, from_logits=True), metrics=[keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.MeanIoU(num_classes=2)])\n",
        "# Save best model\n",
        "callback = [\n",
        "    keras.callbacks.ModelCheckpoint(\"teeth_segmentation.keras\", \n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "teeth_model = model.fit(train_orig, train_teeth,\n",
        "                        epochs=64,\n",
        "                        callbacks=callback,\n",
        "                        batch_size=32,\n",
        "                        validation_data=(val_orig, val_teeth))"
      ],
      "metadata": {
        "id": "yIipWw2eHnOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss of the model\n",
        "loss = teeth_model.history['loss']\n",
        "val_loss = teeth_model.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(teeth_model.epoch, loss, label='Training loss')\n",
        "plt.plot(teeth_model.epoch, val_loss, label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "RIZ6n4wZIkaY",
        "outputId": "21ee5c56-78fd-42cd-c1d9-6db0e12f7a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the test set\n",
        "test_teeth_model = model.evaluate(test_orig, test_teeth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8M-OQVJJWw-",
        "outputId": "c4b515b1-722b-460f-aaf8-d21020b7ad19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 150ms/step - loss: 0.3849 - precision_1: 0.8963 - recall_1: 0.9185 - mean_io_u_1: 0.8301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model():\n",
        "  # Extract decoder path\n",
        "  down0 = base.get_layer('input_1').output\n",
        "  down1 = base.get_layer('conv1_conv').output\n",
        "  down2 = base.get_layer('conv2_block3_1_relu').output\n",
        "  down3 = base.get_layer('conv3_block4_1_relu').output\n",
        "  x = base.get_layer('conv4_block6_1_relu').output \n",
        "  conv6 = up_block(256, down3, x)\n",
        "  layers.Dropout(0.5)(conv6)\n",
        "  conv7 = up_block(128, down2, conv6)\n",
        "  layers.Dropout(0.5)(conv7)\n",
        "  conv8 = up_block(64, down1, conv7)\n",
        "  layers.Dropout(0.5)(conv8)\n",
        "  conv9 = up_block(32, down0, conv8)\n",
        "  layers.Dropout(0.5)(conv9)\n",
        "  outputs = layers.Conv2D(1, 1, activation='sigmoid', padding='same')(conv9)\n",
        "\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  return model\n",
        "\n",
        "# Model object for abnormality detection\n",
        "model_ab = unet_model()"
      ],
      "metadata": {
        "id": "geiZEcFtKbY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    dice_coef = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return dice_coef\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coef(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
        "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
        "    tversky = (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
        "    return tversky\n",
        "\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    tversky_loss = 1 - tversky(y_true, y_pred)\n",
        "    return \n",
        "\n",
        "\n",
        "def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n",
        "    tv = tversky(y_true, y_pred)\n",
        "    focal_tv_loss = K.pow((1 - tv), gamma)\n",
        "    return focal_tv_loss"
      ],
      "metadata": {
        "id": "NpxFzobYljN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the model for tooth detection\n",
        "keras.backend.clear_session()\n",
        "#base.trainable = True\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model_ab.compile(optimizer=opt, loss=focal_tversky_loss, metrics=[keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.MeanIoU(num_classes=2)])\n",
        "# Save best model\n",
        "callback = [\n",
        "    keras.callbacks.ModelCheckpoint(\"abnormality_segmentation.keras\", \n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "# Fit the model\n",
        "ab_model = model_ab.fit(sub_train_orig, tf.cast(train_ab, 'float32'),\n",
        "                        epochs=64,\n",
        "                        batch_size=32,\n",
        "                        callbacks=callback,\n",
        "                        validation_data=(sub_val_orig, tf.cast(val_ab, 'float32')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "qQqOr9sZpe4p",
        "outputId": "c44f5a25-2189-43ea-82e6-f8fe949135bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/64\n",
            "51/51 [==============================] - 27s 286ms/step - loss: 0.9625 - precision: 0.0169 - recall: 0.5913 - mean_io_u: 0.4924 - val_loss: 0.9562 - val_precision: 0.0186 - val_recall: 0.9393 - val_mean_io_u: 0.4916\n",
            "Epoch 2/64\n",
            "51/51 [==============================] - 13s 257ms/step - loss: 0.9545 - precision: 0.0223 - recall: 0.7398 - mean_io_u: 0.4924 - val_loss: 0.9491 - val_precision: 0.1135 - val_recall: 0.0055 - val_mean_io_u: 0.4916\n",
            "Epoch 3/64\n",
            "51/51 [==============================] - 13s 257ms/step - loss: 0.9335 - precision: 0.0369 - recall: 0.8094 - mean_io_u: 0.4924 - val_loss: 0.9435 - val_precision: 0.0250 - val_recall: 0.8499 - val_mean_io_u: 0.4916\n",
            "Epoch 4/64\n",
            "51/51 [==============================] - 13s 247ms/step - loss: 0.9099 - precision: 0.0558 - recall: 0.8766 - mean_io_u: 0.4924 - val_loss: 0.9543 - val_precision: 0.0190 - val_recall: 0.9948 - val_mean_io_u: 0.4913\n",
            "Epoch 5/64\n",
            "51/51 [==============================] - 13s 247ms/step - loss: 0.8845 - precision: 0.0763 - recall: 0.9151 - mean_io_u: 0.4925 - val_loss: 0.9533 - val_precision: 0.0195 - val_recall: 0.9927 - val_mean_io_u: 0.4916\n",
            "Epoch 6/64\n",
            "45/51 [=========================>....] - ETA: 1s - loss: 0.8700 - precision: 0.0915 - recall: 0.9350 - mean_io_u: 0.4963"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-60ab2abbc68d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                         validation_data=(sub_val_orig, tf.cast(val_ab, 'float32')))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_to_img(model_ab.predict(sub_val_orig)[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "oxQj3LUNUEm5",
        "outputId": "a45dd3ae-6f05-469e-c9f3-230e8b09ce74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7FCB72EBF490>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAEVUlEQVR4nO3dTWskRRzH8X91T/fMmDGbWZNV2DUiPlx2WR/w4SAIexPBi54Fz74ET57Us7d9C4IuCCqLLhpN9iISWMEsi8vsk0NQYx5mknno6SoPZgIqpCtDTWar5vs5zaEzVH5T1V1dXV0lAgAAAAAAAAAAAAAAAAAAUExNugCjiNx9lVI+JuAwgCiOPEygVHSAEjGW3+VlDSgIIEpmqv1WzyoCVTImd1GmY3V4AKr85BsvZF9d2rFJQKWSa9va4onkuc93skHv59dTm4Pn6mUfG8EhVO39v3Ktdd76cM7i6LQcj71Ixys+fzPXWmuts6WF4h83igOrAJK+09b78sv1wsO9vAocKn5texiAzi5WJl2cCTi5kh0k8OfzDjtNvoje2tRaa2O01vnSqUkXZwLmr+Zaa2OM1rr1dmG3MTzqbOsggPxHiyuBdwratVn7WA9vBtTi41N4FpDK9YMq0PuoNunSuFf4m3Y/OPgYPzMbXhsortSf9Yaf1FyAXYHiAHavD08C+l573MU5fsUBmPeMiDEiYta7gd3titWQ2NVhGzAbg7GWZSIsAthZ2v/QWe4demCwzv5zQ5Avz4d3EbCS3NZaa915N8SusE3fbrAqIiJ7q/4NeRazCcB8YUTENBvhXQMsH4xcG4iIXt4ec1kmwiqAZl9Eulf6Yy7LRFgF0M1EzN7dEFuAXQC7m8bkzeb0BpCt9getH7amN4D8yu+b1y51xl2WibDr2/zaSL+7EWIvwDIAc/Mb/fVGkC3AblqLqj+9d7sdZg2wu71Jy1lfj7kk97XwHnseUXiPPY9o2v9/AAAAeEEdadZ+eJ3cOI0GA/tJ28E97Yoq9VJ7t2+dQGgBqNq5l6Nba/d2bYdvQgsgWnzzJd2of3/Xdi5HaAEkL144Y06V/9iwe8slvADUTCWR6kxsfRIMbepj+thcpVp/4qmq7eUtsABU9XS1VKosnDs5pQFI705XG6P7me0fBHYOMO1PFl+t7P3y5fq0XgbzxqfJfPPySmtaO0Kmu7b08J2ftqwf4wR3L6CSWrnf7ltfBoMLQCTan9kLAAAAAAAAAAAAAAAAADjc1L81DwAAAAAAgPuD04EqD98ej2KXhfYxgNTlCqf+BaCSWsXh1p4eBhAnqcvtot191XFJ5k6k7tqAfwGopDbrMAD/FlAwWdflIt8eBrC3rhxu+eVhAHlHOawC/p0DhnvfOeJfDRCTG4cr3fsYwEAcbnLv4QNwFbkMwEdMWwAAAP8yaucgjD5FFMXKaKNHWEfPw3uB/4vSByrxoNfL8qN3kUMIIJpdPP9IZavZaG7bryQ5FEAAauaVC88+VO7cWvm2a72a7gEfB0T+S+W7rU4uurUzwpZ4IZwE4xMLj545LTdWf+tNZwAqLpWrD0Zb26PsiRhCABKpOC5JPxtlpCyIAEQpUTLaSGEYAYgox4PFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAI38DpGF0ayHPuGIAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_to_img(val_ab[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "2PBcWpOULp4a",
        "outputId": "15954aaa-8149-4ce9-c913-0dca020e54af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7FCAE16E0E50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAABlElEQVR4nO3bwVKDQBAEULH8/1/GWyqBZRcuTtnz3sGEyGGm06BWxa8vAAAAAAAAAAAAiLUtz9hvnvdPfa9O2D8e8qwC2E9Pwiwb8BKawCKA0K3fzAPYLw9iTAPIXPnTLIAO+z+4CYaaBNCiAJMAzvtHJvJz8XrksiMXDWizv5vgOIA+BRgH0Gj/YQCd9h8F0Gp/N8FzAJMCJHZDA6oHqHYKILHmMxpwOO5WAA0QQPUA1Q4BtLsFaIAAqgeoJoDqAap9BtDvh4AGCKB6gGoCqB6gmgCenJz4aUkNqB6gmgCqB6gmgOoBqgmgeoBqTwJI/D1IAwRQPUC1BwFE3gI04H4AmQXQgNsBhBbgdgCp+98NIHb/mwHk7n/5LzPvgte/1YDo/dcNyF7/2ID0bQdWl0B8JIsA4vc/BrBNDxP5W2D2zQYFOAWwXTyP5RI4vtDibX8zaUCPKFwCp1d6vPEvgwZsHw/pRpfA9vrS1t7wU9MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAf+0X8Qcco7/g+IkAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}